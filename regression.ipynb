{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import sklearn\n",
    "import warnings\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from typing import Protocol, Callable\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_dim_converter: Callable[[numpy.ndarray], numpy.ndarray] = lambda x: x.reshape(-1, 1) if x.ndim == 1 else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Metrics:\n",
    "    \"class that represents each model test error metrics\"\n",
    "    mse: float\n",
    "    mae: float\n",
    "    r2_score: float\n",
    "\n",
    "class Model(Protocol):\n",
    "\n",
    "    def fit(self, x: numpy.ndarray, y: numpy.ndarray) -> None:\n",
    "        \"represents fitting the model\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def transform(self, x: numpy.ndarray) -> numpy.ndarray:\n",
    "        \"represents the transform function\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def fit_transform(self, x: numpy.ndarray, y: numpy.ndarray) -> numpy.ndarray:\n",
    "        \"represents the fit and transform function\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "class ModelTypes(Enum):\n",
    "    LINEAR = \"Linear\"\n",
    "    RANDOM_FORREST = \"Random Forrest\"\n",
    "    RIDGE = \"Ridge\"\n",
    "    LASSO = \"Lasso\"\n",
    "\n",
    "class DataTransformer(Protocol):\n",
    "    \"Basic representation of the dataset normalizer\"\n",
    "\n",
    "    def fit(self, data: numpy.ndarray) -> None:\n",
    "        \"fit the transformer model\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def fit_transform(self, data: numpy.ndarray) -> numpy.ndarray:\n",
    "        \"fit the transformer model and return the normalized dataset\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def transform(self, data: numpy.ndarray) -> numpy.ndarray:\n",
    "        \"transforms the input data\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def inv_transform(self, data: numpy.ndarray) -> numpy.ndarray:\n",
    "        \"inversely transforms the data\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "class STDScaler:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._transformer: sklearn.preprocessing._data.StandardScaler = StandardScaler()\n",
    "\n",
    "    def fit(self, data: numpy.ndarray) -> None:\n",
    "        self._transformer.fit(data)\n",
    "\n",
    "    def fit_transform(self, data: numpy.ndarray) -> numpy.ndarray:\n",
    "        return self._transformer.fit_transform(data)\n",
    "\n",
    "    def transform(self, data: numpy.ndarray) -> numpy.ndarray:\n",
    "        return self._transformer.transform(data)\n",
    "    \n",
    "    def inv_transform(self, data: numpy.ndarray) -> numpy.ndarray:\n",
    "        return self._transformer.inverse_transform(data)\n",
    "\n",
    "class ModelPipeline(Protocol):\n",
    "    \"represents an end to end pipeline of a model\"\n",
    "    feature_scaler: DataTransformer\n",
    "    target_scaler: DataTransformer \n",
    "\n",
    "    def fit(self, feature: numpy.ndarray, target: numpy.ndarray, hparams: dict[str, int|float]=dict()) -> None:\n",
    "        \"fits the pipeline\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def forward(self, feature: numpy.ndarray) -> numpy.ndarray:\n",
    "        \"calculates the forward path\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "class LinearModel(ModelPipeline):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._model: Model\n",
    "        self._pipeline: Callable[[numpy.ndarray], numpy.ndarray] \n",
    "    \n",
    "    def fit(self, feature: numpy.ndarray, target: numpy.ndarray, hparams: dict[str, int|float]=dict()) -> None:\n",
    "        self._model = LinearRegression()\n",
    "        self._model.fit(self.feature_scaler.transform(feature), self.target_scaler.transform(target))\n",
    "        self._pipeline = lambda x: self.target_scaler.inv_transform(double_dim_converter(self._model.predict(self.feature_scaler.transform(x))))\n",
    "    \n",
    "    def forward(self, feature: numpy.ndarray) -> numpy.ndarray:\n",
    "        return self._pipeline(feature)\n",
    "\n",
    "class RandomForrestModel(ModelPipeline):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._model: Model\n",
    "        self._pipeline: Callable[[numpy.ndarray], numpy.ndarray] \n",
    "    \n",
    "    def fit(self, feature: numpy.ndarray, target: numpy.ndarray, hparams: dict[str, int|float]=dict()) -> None:\n",
    "        self._model = RandomForestRegressor\n",
    "        grid_search = GridSearchCV(self._model(), hparams, verbose=3)\n",
    "        grid_search.fit(self.feature_scaler.transform(feature), self.target_scaler.transform(target))\n",
    "        self._model = grid_search.best_estimator_\n",
    "        self._pipeline = lambda x: self.target_scaler.inv_transform(double_dim_converter(self._model.predict(self.feature_scaler.transform(x))))\n",
    "    \n",
    "    def forward(self, feature: numpy.ndarray) -> numpy.ndarray:\n",
    "        return self._pipeline(feature)\n",
    "\n",
    "class RidgeModel(ModelPipeline):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._model: Model\n",
    "        self._pipeline: Callable[[numpy.ndarray], numpy.ndarray] \n",
    "    \n",
    "    def fit(self, feature: numpy.ndarray, target: numpy.ndarray, hparams: dict[str, int|float]=dict()) -> None:\n",
    "        self._model = Ridge\n",
    "        grid_search = GridSearchCV(self._model(), hparams)\n",
    "        grid_search.fit(self.feature_scaler.transform(feature), self.target_scaler.transform(target))\n",
    "        self._model = grid_search.best_estimator_\n",
    "        self._pipeline = lambda x: self.target_scaler.inv_transform(double_dim_converter(self._model.predict(self.feature_scaler.transform(x))))\n",
    "    \n",
    "    def forward(self, feature: numpy.ndarray) -> numpy.ndarray:\n",
    "        return self._pipeline(feature)\n",
    "\n",
    "class LassoModel(ModelPipeline):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._model: Model\n",
    "        self._pipeline: Callable[[numpy.ndarray], numpy.ndarray] \n",
    "    \n",
    "    def fit(self, feature: numpy.ndarray, target: numpy.ndarray, hparams: dict[str, int|float]=dict()) -> None:\n",
    "        self._model = Lasso\n",
    "        grid_search = GridSearchCV(self._model(), hparams)\n",
    "        grid_search.fit(self.feature_scaler.transform(feature), self.target_scaler.transform(target))\n",
    "        self._model = grid_search.best_estimator_\n",
    "        self._pipeline = lambda x: self.target_scaler.inv_transform(double_dim_converter(self._model.predict(self.feature_scaler.transform(x))))\n",
    "    \n",
    "    def forward(self, feature: numpy.ndarray) -> numpy.ndarray:\n",
    "        return self._pipeline(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "\n",
    "DS_PATH = \"1.xlsx\"\n",
    "TARGET = \"Vs\"\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "SEED = 0\n",
    "RANDOM_FORREST_HPARAMS = {\"max_depth\": list(range(1, 20))}\n",
    "RIDGE_HPARAMS = {\"alpha\":list(numpy.arange(0.1, 2.0, 0.1))}\n",
    "LASSO_HPARAMS = {\"alpha\":list(numpy.arange(0.1, 2.0, 0.1))}\n",
    "\n",
    "with open(DS_PATH, \"rb\") as afile:\n",
    "    df = pandas.read_excel(afile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_err_metrics(y_true: numpy.ndarray, y_pred: numpy.ndarray):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2_metric = r2_score(y_true, y_pred)\n",
    "    return Metrics(mse, mae, r2_metric)\n",
    "\n",
    "def data_train_test_split(df: pandas.core.frame.DataFrame, test_size: float, seed: int) -> tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray]:\n",
    "\n",
    "    X = double_dim_converter(df.drop(TARGET, axis=1).to_numpy())\n",
    "    y = double_dim_converter(df[TARGET].to_numpy())\n",
    "    return train_test_split(X, y, test_size=test_size, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_targets, test_targets = data_train_test_split(df, TEST_SIZE, SEED)\n",
    "\n",
    "feature_scaler = STDScaler()\n",
    "target_scaler = STDScaler()\n",
    "\n",
    "feature_scaler.fit(train_features)\n",
    "target_scaler.fit(train_targets)\n",
    "\n",
    "\n",
    "ModelPipeline.feature_scaler = feature_scaler\n",
    "ModelPipeline.target_scaler = target_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting the Linear model...\n",
      "fitting the Random Forrest model...\n",
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n",
      "[CV 1/5] END .......................max_depth=1;, score=0.684 total time=   0.4s\n",
      "[CV 2/5] END .......................max_depth=1;, score=0.666 total time=   0.3s\n",
      "[CV 3/5] END .......................max_depth=1;, score=0.668 total time=   0.2s\n",
      "[CV 4/5] END .......................max_depth=1;, score=0.690 total time=   0.2s\n",
      "[CV 5/5] END .......................max_depth=1;, score=0.667 total time=   0.2s\n",
      "[CV 1/5] END .......................max_depth=2;, score=0.923 total time=   0.3s\n",
      "[CV 2/5] END .......................max_depth=2;, score=0.917 total time=   0.3s\n",
      "[CV 3/5] END .......................max_depth=2;, score=0.908 total time=   0.4s\n",
      "[CV 4/5] END .......................max_depth=2;, score=0.933 total time=   0.3s\n",
      "[CV 5/5] END .......................max_depth=2;, score=0.912 total time=   0.3s\n",
      "[CV 1/5] END .......................max_depth=3;, score=0.987 total time=   0.4s\n",
      "[CV 2/5] END .......................max_depth=3;, score=0.985 total time=   0.3s\n",
      "[CV 3/5] END .......................max_depth=3;, score=0.980 total time=   0.3s\n",
      "[CV 4/5] END .......................max_depth=3;, score=0.987 total time=   0.4s\n",
      "[CV 5/5] END .......................max_depth=3;, score=0.980 total time=   0.4s\n",
      "[CV 1/5] END .......................max_depth=4;, score=0.998 total time=   0.4s\n",
      "[CV 2/5] END .......................max_depth=4;, score=0.998 total time=   0.4s\n",
      "[CV 3/5] END .......................max_depth=4;, score=0.997 total time=   0.4s\n",
      "[CV 4/5] END .......................max_depth=4;, score=0.998 total time=   0.4s\n",
      "[CV 5/5] END .......................max_depth=4;, score=0.997 total time=   0.4s\n",
      "[CV 1/5] END .......................max_depth=5;, score=0.999 total time=   0.4s\n",
      "[CV 2/5] END .......................max_depth=5;, score=1.000 total time=   0.5s\n",
      "[CV 3/5] END .......................max_depth=5;, score=0.999 total time=   0.4s\n",
      "[CV 4/5] END .......................max_depth=5;, score=0.999 total time=   0.4s\n",
      "[CV 5/5] END .......................max_depth=5;, score=0.999 total time=   0.5s\n",
      "[CV 1/5] END .......................max_depth=6;, score=0.999 total time=   0.5s\n",
      "[CV 2/5] END .......................max_depth=6;, score=1.000 total time=   0.5s\n",
      "[CV 3/5] END .......................max_depth=6;, score=1.000 total time=   0.5s\n",
      "[CV 4/5] END .......................max_depth=6;, score=0.999 total time=   0.5s\n",
      "[CV 5/5] END .......................max_depth=6;, score=0.999 total time=   0.6s\n",
      "[CV 1/5] END .......................max_depth=7;, score=1.000 total time=   0.5s\n",
      "[CV 2/5] END .......................max_depth=7;, score=1.000 total time=   0.6s\n",
      "[CV 3/5] END .......................max_depth=7;, score=1.000 total time=   0.6s\n",
      "[CV 4/5] END .......................max_depth=7;, score=0.999 total time=   0.6s\n",
      "[CV 5/5] END .......................max_depth=7;, score=0.999 total time=   0.5s\n",
      "[CV 1/5] END .......................max_depth=8;, score=1.000 total time=   0.6s\n",
      "[CV 2/5] END .......................max_depth=8;, score=1.000 total time=   0.5s\n",
      "[CV 3/5] END .......................max_depth=8;, score=1.000 total time=   0.5s\n",
      "[CV 4/5] END .......................max_depth=8;, score=0.999 total time=   0.5s\n",
      "[CV 5/5] END .......................max_depth=8;, score=0.999 total time=   0.5s\n",
      "[CV 1/5] END .......................max_depth=9;, score=1.000 total time=   0.6s\n",
      "[CV 2/5] END .......................max_depth=9;, score=1.000 total time=   0.6s\n",
      "[CV 3/5] END .......................max_depth=9;, score=1.000 total time=   0.6s\n",
      "[CV 4/5] END .......................max_depth=9;, score=0.999 total time=   0.6s\n",
      "[CV 5/5] END .......................max_depth=9;, score=0.999 total time=   0.6s\n",
      "[CV 1/5] END ......................max_depth=10;, score=1.000 total time=   0.6s\n",
      "[CV 2/5] END ......................max_depth=10;, score=1.000 total time=   0.6s\n",
      "[CV 3/5] END ......................max_depth=10;, score=1.000 total time=   0.6s\n",
      "[CV 4/5] END ......................max_depth=10;, score=1.000 total time=   0.6s\n",
      "[CV 5/5] END ......................max_depth=10;, score=0.999 total time=   0.6s\n",
      "[CV 1/5] END ......................max_depth=11;, score=1.000 total time=   0.6s\n",
      "[CV 2/5] END ......................max_depth=11;, score=1.000 total time=   0.6s\n",
      "[CV 3/5] END ......................max_depth=11;, score=1.000 total time=   0.7s\n",
      "[CV 4/5] END ......................max_depth=11;, score=1.000 total time=   0.8s\n",
      "[CV 5/5] END ......................max_depth=11;, score=0.999 total time=   0.7s\n",
      "[CV 1/5] END ......................max_depth=12;, score=1.000 total time=   0.7s\n",
      "[CV 2/5] END ......................max_depth=12;, score=1.000 total time=   0.6s\n",
      "[CV 3/5] END ......................max_depth=12;, score=1.000 total time=   0.8s\n",
      "[CV 4/5] END ......................max_depth=12;, score=0.999 total time=   0.7s\n",
      "[CV 5/5] END ......................max_depth=12;, score=0.999 total time=   0.7s\n",
      "[CV 1/5] END ......................max_depth=13;, score=1.000 total time=   0.8s\n",
      "[CV 2/5] END ......................max_depth=13;, score=1.000 total time=   0.6s\n",
      "[CV 3/5] END ......................max_depth=13;, score=1.000 total time=   0.7s\n",
      "[CV 4/5] END ......................max_depth=13;, score=0.999 total time=   0.6s\n",
      "[CV 5/5] END ......................max_depth=13;, score=0.999 total time=   0.6s\n",
      "[CV 1/5] END ......................max_depth=14;, score=1.000 total time=   0.8s\n",
      "[CV 2/5] END ......................max_depth=14;, score=1.000 total time=   0.8s\n",
      "[CV 3/5] END ......................max_depth=14;, score=1.000 total time=   0.6s\n",
      "[CV 4/5] END ......................max_depth=14;, score=0.999 total time=   0.6s\n",
      "[CV 5/5] END ......................max_depth=14;, score=0.999 total time=   0.6s\n",
      "[CV 1/5] END ......................max_depth=15;, score=0.999 total time=   0.6s\n",
      "[CV 2/5] END ......................max_depth=15;, score=1.000 total time=   0.6s\n",
      "[CV 3/5] END ......................max_depth=15;, score=1.000 total time=   0.6s\n",
      "[CV 4/5] END ......................max_depth=15;, score=0.999 total time=   0.6s\n",
      "[CV 5/5] END ......................max_depth=15;, score=0.999 total time=   0.6s\n",
      "[CV 1/5] END ......................max_depth=16;, score=1.000 total time=   0.6s\n",
      "[CV 2/5] END ......................max_depth=16;, score=1.000 total time=   0.6s\n",
      "[CV 3/5] END ......................max_depth=16;, score=1.000 total time=   0.6s\n",
      "[CV 4/5] END ......................max_depth=16;, score=0.999 total time=   0.6s\n",
      "[CV 5/5] END ......................max_depth=16;, score=0.999 total time=   0.6s\n",
      "[CV 1/5] END ......................max_depth=17;, score=1.000 total time=   0.6s\n",
      "[CV 2/5] END ......................max_depth=17;, score=1.000 total time=   0.7s\n",
      "[CV 3/5] END ......................max_depth=17;, score=1.000 total time=   0.6s\n",
      "[CV 4/5] END ......................max_depth=17;, score=1.000 total time=   0.6s\n",
      "[CV 5/5] END ......................max_depth=17;, score=0.999 total time=   0.6s\n",
      "[CV 1/5] END ......................max_depth=18;, score=0.999 total time=   0.6s\n",
      "[CV 2/5] END ......................max_depth=18;, score=1.000 total time=   0.6s\n",
      "[CV 3/5] END ......................max_depth=18;, score=1.000 total time=   0.6s\n",
      "[CV 4/5] END ......................max_depth=18;, score=1.000 total time=   0.6s\n",
      "[CV 5/5] END ......................max_depth=18;, score=0.999 total time=   0.6s\n",
      "[CV 1/5] END ......................max_depth=19;, score=0.999 total time=   0.6s\n",
      "[CV 2/5] END ......................max_depth=19;, score=1.000 total time=   0.6s\n",
      "[CV 3/5] END ......................max_depth=19;, score=1.000 total time=   0.6s\n",
      "[CV 4/5] END ......................max_depth=19;, score=0.999 total time=   0.6s\n",
      "[CV 5/5] END ......................max_depth=19;, score=0.999 total time=   0.6s\n",
      "fitting the Ridge model...\n",
      "fitting the Lasso model...\n",
      "{<ModelTypes.LINEAR: 'Linear'>: Metrics(mse=0.0005052634987453016, mae=0.014597020597234707, r2_score=0.9901937660350684), <ModelTypes.RANDOM_FORREST: 'Random Forrest'>: Metrics(mse=1.3386070108277267e-05, mae=0.0014502292602868957, r2_score=0.9997402010323747), <ModelTypes.RIDGE: 'Ridge'>: Metrics(mse=0.0005071245966387821, mae=0.01461954346068169, r2_score=0.990157645552547), <ModelTypes.LASSO: 'Lasso'>: Metrics(mse=0.001129666512189448, mae=0.026298041139860666, r2_score=0.9780752535095313)}\n"
     ]
    }
   ],
   "source": [
    "model_metrics: dict[ModelTypes, Metrics] = {}\n",
    "\n",
    "model_type = ModelTypes.LINEAR\n",
    "print(f\"fitting the {model_type.value} model...\")\n",
    "linear_pipeline = LinearModel()\n",
    "linear_pipeline.fit(train_features, train_targets)\n",
    "model_metrics[ModelTypes.LINEAR] = calculate_err_metrics(test_targets, linear_pipeline.forward(test_features))\n",
    "\n",
    "model_type = ModelTypes.RANDOM_FORREST\n",
    "print(f\"fitting the {model_type.value} model...\")\n",
    "random_forrest_pipeline = RandomForrestModel()\n",
    "random_forrest_pipeline.fit(train_features, train_targets, RANDOM_FORREST_HPARAMS)\n",
    "model_metrics[model_type] = calculate_err_metrics(test_targets, random_forrest_pipeline.forward(test_features))\n",
    "\n",
    "model_type = ModelTypes.RIDGE\n",
    "print(f\"fitting the {model_type.value} model...\")\n",
    "ridge_pipeline = RidgeModel()\n",
    "ridge_pipeline.fit(train_features, train_targets, RIDGE_HPARAMS)\n",
    "model_metrics[model_type] = calculate_err_metrics(test_targets, ridge_pipeline.forward(test_features))\n",
    "\n",
    "model_type = ModelTypes.LASSO\n",
    "print(f\"fitting the {model_type.value} model...\")\n",
    "lasso_pipeline = LassoModel()\n",
    "lasso_pipeline.fit(train_features, train_targets, LASSO_HPARAMS)\n",
    "model_metrics[model_type] = calculate_err_metrics(test_targets, lasso_pipeline.forward(test_features))\n",
    "\n",
    "print(model_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
