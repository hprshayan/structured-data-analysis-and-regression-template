{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import sklearn\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from typing import Protocol, Callable\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_dim_converter: Callable[[numpy.ndarray], numpy.ndarray] = lambda x: x.reshape(-1, 1) if x.ndim == 1 else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Metrics:\n",
    "    \"class that represents each model test error metrics\"\n",
    "    mse: float\n",
    "    mae: float\n",
    "    r2_score: float\n",
    "\n",
    "class Model(Protocol):\n",
    "\n",
    "    def fit(self, x: numpy.ndarray, y: numpy.ndarray) -> None:\n",
    "        \"represents fitting the model\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def transform(self, x: numpy.ndarray) -> numpy.ndarray:\n",
    "        \"represents the transform function\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def fit_transform(self, x: numpy.ndarray, y: numpy.ndarray) -> numpy.ndarray:\n",
    "        \"represents the fit and transform function\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "class ModelTypes(Enum):\n",
    "    LINEAR = \"Linear\"\n",
    "    POLYNOMIAL = \"Polynomial\"\n",
    "    RANDOM_FORREST = \"Random Forrest\"\n",
    "    RIDGE = \"Ridge\"\n",
    "    LASSO = \"Lasso\"\n",
    "\n",
    "class DataTransformer(Protocol):\n",
    "    \"Basic representation of the dataset normalizer\"\n",
    "\n",
    "    def fit(self, data: numpy.ndarray) -> None:\n",
    "        \"fit the transformer model\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def fit_transform(self, data: numpy.ndarray) -> numpy.ndarray:\n",
    "        \"fit the transformer model and return the normalized dataset\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def transform(self, data: numpy.ndarray) -> numpy.ndarray:\n",
    "        \"transforms the input data\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def inv_transform(self, data: numpy.ndarray) -> numpy.ndarray:\n",
    "        \"inversely transforms the data\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "class STDScaler:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._transformer: sklearn.preprocessing._data.StandardScaler = StandardScaler()\n",
    "\n",
    "    def fit(self, data: numpy.ndarray) -> None:\n",
    "        self._transformer.fit(data)\n",
    "\n",
    "    def fit_transform(self, data: numpy.ndarray) -> numpy.ndarray:\n",
    "        return self._transformer.fit_transform(data)\n",
    "\n",
    "    def transform(self, data: numpy.ndarray) -> numpy.ndarray:\n",
    "        return self._transformer.transform(data)\n",
    "    \n",
    "    def inv_transform(self, data: numpy.ndarray) -> numpy.ndarray:\n",
    "        return self._transformer.inverse_transform(data)\n",
    "\n",
    "class ModelPipeline(Protocol):\n",
    "    \"represents an end to end pipeline of a model\"\n",
    "\n",
    "    def build_fit(self, feature: numpy.ndarray, target: numpy.ndarray, feature_scaler: DataTransformer, target_scaler: DataTransformer) -> None:\n",
    "        \"build and fits the pipeline\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def forward(self, feature: numpy.ndarray) -> numpy.ndarray:\n",
    "        \"calculates the forward path\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "class LinearModel:\n",
    "\n",
    "    def __init__(self, hparams: dict[str, int|float]=dict()) -> None:\n",
    "        self._model: Model = LinearRegression(**hparams)\n",
    "        self._pipeline: Callable[[numpy.ndarray], numpy.ndarray] \n",
    "    \n",
    "    def build_fit(self, feature: numpy.ndarray, target: numpy.ndarray, feature_scaler: DataTransformer, target_scaler: DataTransformer) -> None:\n",
    "        self._model.fit(feature_scaler.transform(feature), target_scaler.transform(target))\n",
    "        self._pipeline = lambda x: target_scaler.inv_transform(double_dim_converter(self._model.predict(feature_scaler.transform(x))))\n",
    "    \n",
    "    def forward(self, feature: numpy.ndarray) -> numpy.ndarray:\n",
    "        return self._pipeline(feature)\n",
    "\n",
    "class PolynomialModel:\n",
    "\n",
    "    def __init__(self, hparams: dict[str, int|float]=dict()) -> None:\n",
    "        self._model: Model = LinearRegression()\n",
    "        self._pipeline: Callable[[numpy.ndarray], numpy.ndarray] \n",
    "        self._poly_creator = PolynomialFeatures(**hparams)\n",
    "    \n",
    "    def build_fit(self, feature: numpy.ndarray, target: numpy.ndarray, feature_scaler: DataTransformer, target_scaler: DataTransformer) -> None:\n",
    "        poly_train_features = self._poly_creator.fit_transform(feature)\n",
    "        poly_feature_scaler = STDScaler()\n",
    "\n",
    "        poly_feature_scaler.fit(poly_train_features)\n",
    "        self._model.fit(poly_feature_scaler.transform(poly_train_features), target_scaler.transform(target))\n",
    "        self._pipeline = lambda x: target_scaler.inv_transform(double_dim_converter(self._model.predict(poly_feature_scaler.transform(self._poly_creator.transform(x)))))\n",
    "    \n",
    "    def forward(self, feature: numpy.ndarray) -> numpy.ndarray:\n",
    "        return self._pipeline(feature)\n",
    "\n",
    "class RandomForrestModel:\n",
    "\n",
    "    def __init__(self, hparams: dict[str, int|float]=dict()) -> None:\n",
    "        self._model: Model = RandomForestRegressor(**hparams)\n",
    "        self._pipeline: Callable[[numpy.ndarray], numpy.ndarray] \n",
    "    \n",
    "    def build_fit(self, feature: numpy.ndarray, target: numpy.ndarray, feature_scaler: DataTransformer, target_scaler: DataTransformer) -> None:\n",
    "        self._model.fit(feature_scaler.transform(feature), target_scaler.transform(target))\n",
    "        self._pipeline = lambda x: target_scaler.inv_transform(double_dim_converter(self._model.predict(feature_scaler.transform(x))))\n",
    "    \n",
    "    def forward(self, feature: numpy.ndarray) -> numpy.ndarray:\n",
    "        return self._pipeline(feature)\n",
    "\n",
    "class RidgeModel:\n",
    "\n",
    "    def __init__(self, hparams: dict[str, int|float]=dict()) -> None:\n",
    "        self._model: Model = Ridge(**hparams)\n",
    "        self._pipeline: Callable[[numpy.ndarray], numpy.ndarray] \n",
    "    \n",
    "    def build_fit(self, feature: numpy.ndarray, target: numpy.ndarray, feature_scaler: DataTransformer, target_scaler: DataTransformer) -> None:\n",
    "        self._model.fit(feature_scaler.transform(feature), target_scaler.transform(target))\n",
    "        self._pipeline = lambda x: target_scaler.inv_transform(double_dim_converter(self._model.predict(feature_scaler.transform(x))))\n",
    "    \n",
    "    def forward(self, feature: numpy.ndarray) -> numpy.ndarray:\n",
    "        return self._pipeline(feature)\n",
    "\n",
    "class LassoModel:\n",
    "\n",
    "    def __init__(self, hparams: dict[str, int|float]=dict()) -> None:\n",
    "        self._model: Model = Lasso(**hparams)\n",
    "        self._pipeline: Callable[[numpy.ndarray], numpy.ndarray] \n",
    "    \n",
    "    def build_fit(self, feature: numpy.ndarray, target: numpy.ndarray, feature_scaler: DataTransformer, target_scaler: DataTransformer) -> None:\n",
    "        self._model.fit(feature_scaler.transform(feature), target_scaler.transform(target))\n",
    "        self._pipeline = lambda x: target_scaler.inv_transform(double_dim_converter(self._model.predict(feature_scaler.transform(x))))\n",
    "    \n",
    "    def forward(self, feature: numpy.ndarray) -> numpy.ndarray:\n",
    "        return self._pipeline(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_PATH = \"1.xlsx\"\n",
    "TARGET = \"Vs\"\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "SEED = 0\n",
    "POLYNOMIAL_DEGREE = 2\n",
    "RANDOM_FORREST_MAX_DEPTH = 5\n",
    "RIDGE_ALPHA = 1\n",
    "LASSO_ALPHA = 0.1\n",
    "\n",
    "with open(DS_PATH, \"rb\") as afile:\n",
    "    df = pandas.read_excel(afile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_err_metrics(y_true: numpy.ndarray, y_pred: numpy.ndarray):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2_metric = r2_score(y_true, y_pred)\n",
    "    return Metrics(mse, mae, r2_metric)\n",
    "\n",
    "def data_train_test_split(df: pandas.core.frame.DataFrame, test_size: float, seed: int) -> tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray]:\n",
    "\n",
    "    train_df, test_df = train_test_split(df, test_size=test_size, shuffle=True, random_state=seed)\n",
    "    train_features = double_dim_converter(train_df.drop(TARGET, axis=1).to_numpy())\n",
    "    train_targets = double_dim_converter(train_df[TARGET].to_numpy())\n",
    "    test_features = double_dim_converter(test_df.drop(TARGET, axis=1).to_numpy())\n",
    "    test_targets = double_dim_converter(test_df[TARGET].to_numpy())\n",
    "\n",
    "    return train_features, train_targets, test_features, test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_targets, test_features, test_targets = data_train_test_split(df, TEST_SIZE, SEED)\n",
    "\n",
    "feature_scaler = STDScaler()\n",
    "target_scaler = STDScaler()\n",
    "\n",
    "feature_scaler.fit(train_features)\n",
    "target_scaler.fit(train_targets)\n",
    "\n",
    "model_metrics: dict[ModelTypes, Metrics] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error metrics of ModelTypes.LINEAR regression model:\n",
      "Metrics(mse=0.0005052634987468958, mae=0.014597020597226925, r2_score=0.9901937660350374)\n",
      "\n",
      "\n",
      "Test error metrics of ModelTypes.POLYNOMIAL regression model:\n",
      "Metrics(mse=3.3779620004102484e-06, mae=0.0011082465714446516, r2_score=0.9999344399787775)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_357988/4112522269.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._model.fit(feature_scaler.transform(feature), target_scaler.transform(target))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error metrics of ModelTypes.RANDOM_FORREST regression model:\n",
      "Metrics(mse=1.1364874043831596e-05, mae=0.001341003696686165, r2_score=0.9997794287255412)\n",
      "\n",
      "\n",
      "Test error metrics of ModelTypes.RIDGE regression model:\n",
      "Metrics(mse=0.0005156030873131474, mae=0.014842693222569443, r2_score=0.9899930936634262)\n",
      "\n",
      "\n",
      "Test error metrics of LASSO regression model:\n",
      "Metrics(mse=0.05182340641895126, mae=0.17948229600945165, r2_score=-0.0057968752263852785)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# linear\n",
    "linear_pipeline = LinearModel()\n",
    "linear_pipeline.build_fit(train_features, train_targets, feature_scaler, target_scaler)\n",
    "metrics = calculate_err_metrics(test_targets, linear_pipeline.forward(test_features))\n",
    "model_metrics[ModelTypes.LINEAR] = metrics\n",
    "print(f\"Test error metrics of {ModelTypes.LINEAR} regression model:\", metrics, \"\\n\", sep=\"\\n\")\n",
    "\n",
    "# polynomial\n",
    "polynomial_pipeline = PolynomialModel()\n",
    "polynomial_pipeline.build_fit(train_features, train_targets, feature_scaler, target_scaler)\n",
    "metrics = calculate_err_metrics(test_targets, polynomial_pipeline.forward(test_features))\n",
    "model_metrics[ModelTypes.POLYNOMIAL] = metrics\n",
    "print(f\"Test error metrics of {ModelTypes.POLYNOMIAL} regression model:\", metrics, \"\\n\", sep=\"\\n\")\n",
    "\n",
    "# random forrest\n",
    "random_forrest_pipeline = RandomForrestModel()\n",
    "random_forrest_pipeline.build_fit(train_features, train_targets, feature_scaler, target_scaler)\n",
    "metrics = calculate_err_metrics(test_targets, random_forrest_pipeline.forward(test_features))\n",
    "model_metrics[ModelTypes.RANDOM_FORREST] = metrics\n",
    "print(f\"Test error metrics of {ModelTypes.RANDOM_FORREST} regression model:\", metrics, \"\\n\", sep=\"\\n\")\n",
    "\n",
    "# ridge\n",
    "ridge_pipeline = RidgeModel()\n",
    "ridge_pipeline.build_fit(train_features, train_targets, feature_scaler, target_scaler)\n",
    "metrics = calculate_err_metrics(test_targets, ridge_pipeline.forward(test_features))\n",
    "model_metrics[ModelTypes.RIDGE] = metrics\n",
    "print(f\"Test error metrics of {ModelTypes.RIDGE} regression model:\", metrics, \"\\n\", sep=\"\\n\")\n",
    "\n",
    "# lasso\n",
    "lasso_pipeline = LassoModel()\n",
    "lasso_pipeline.build_fit(train_features, train_targets, feature_scaler, target_scaler)\n",
    "metrics = calculate_err_metrics(test_targets, lasso_pipeline.forward(test_features))\n",
    "model_metrics[ModelTypes.LASSO] = metrics\n",
    "print(f\"Test error metrics of {ModelTypes.LASSO} regression model:\", metrics, \"\\n\", sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # linear regression\n",
    "# linear_model = LinearRegression().fit(scaled_train_features, scaled_train_targets)\n",
    "\n",
    "# linear_fwd_pipeline: Callable[[numpy.ndarray], numpy.ndarray] = lambda x: target_scaler.inv_transform(linear_model.predict(feature_scaler.transform(x)))\n",
    "\n",
    "# metrics = calculate_err_metrics(test_targets, linear_fwd_pipeline(test_features))\n",
    "# model_metrics[ModelTypes.LINEAR] = metrics\n",
    "# print(\"Test error metrics of linear regression model:\", metrics, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # polynomial regression\n",
    "# # Creating the higher degree features and interactions\n",
    "# poly_creator = PolynomialFeatures(degree=POLYNOMIAL_DEGREE)\n",
    "# poly_train_features = poly_creator.fit_transform(train_features)\n",
    "\n",
    "# poly_feature_scaler = STDScaler()\n",
    "# poly_target_scaler = STDScaler()\n",
    "\n",
    "# poly_scaled_train_features = poly_feature_scaler.fit_transform(poly_train_features)\n",
    "# poly_scaled_train_targets = poly_target_scaler.fit_transform(train_targets)\n",
    "\n",
    "# polynomial_model = LinearRegression().fit(poly_scaled_train_features, poly_scaled_train_targets)\n",
    "\n",
    "# poly_fwd_pipeline: Callable[[numpy.ndarray], numpy.ndarray] = lambda x: poly_target_scaler.inv_transform(polynomial_model.predict(poly_feature_scaler.transform(poly_creator.transform(x))))\n",
    "\n",
    "# metrics = calculate_err_metrics(test_targets, poly_fwd_pipeline(test_features))\n",
    "# model_metrics[ModelTypes.POLYNOMIAL] = metrics\n",
    "# print(\"Test error metrics of polynomial regression model:\", metrics, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random forrest regression\n",
    "# random_forrest_model = RandomForestRegressor(max_depth=RANDOM_FORREST_MAX_DEPTH, random_state=SEED).fit(scaled_train_features, scaled_train_targets)\n",
    "\n",
    "# r_forrest_fwd_pipeline: Callable[[numpy.ndarray], numpy.ndarray] = lambda x: target_scaler.inv_transform(double_dim_converter(random_forrest_model.predict(feature_scaler.transform(x))))\n",
    "\n",
    "# metrics = calculate_err_metrics(test_targets, r_forrest_fwd_pipeline(test_features))\n",
    "# model_metrics[ModelTypes.RANDOM_FORREST] = metrics\n",
    "# print(\"Test error metrics of random forrest regression model:\", metrics, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ridge regression\n",
    "# ridge_model = Ridge(alpha=RIDGE_ALPHA).fit(scaled_train_features, scaled_train_targets)\n",
    "\n",
    "# ridge_fwd_pipeline: Callable[[numpy.ndarray], numpy.ndarray] = lambda x: target_scaler.inv_transform(ridge_model.predict(feature_scaler.transform(x)))\n",
    "\n",
    "# metrics = calculate_err_metrics(test_targets, ridge_fwd_pipeline(test_features))\n",
    "# model_metrics[ModelTypes.RIDGE] = metrics\n",
    "# print(\"Test error metrics of ridge regression model:\", metrics, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso regression\n",
    "# lasso_model = Lasso(alpha=LASSO_ALPHA).fit(scaled_train_features, scaled_train_targets)\n",
    "\n",
    "# lasso_fwd_pipeline: Callable[[numpy.ndarray], numpy.ndarray] = lambda x: target_scaler.inv_transform(double_dim_converter(lasso_model.predict(feature_scaler.transform(x))))\n",
    "\n",
    "# metrics = calculate_err_metrics(test_targets, lasso_fwd_pipeline(test_features))\n",
    "# model_metrics[ModelTypes.LASSO] = metrics\n",
    "# print(\"Test error metrics of lasso regression model:\", metrics, sep=\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
